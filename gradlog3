Using APEX
Set precision to: torch.float16
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
RESCALE_SIZE:  286
Data loader
	Root: .
	Number of images: 1975
	Classes:  ['Hela', 'synthetic_BBBC004', 'Human_USOS_P_20585', 'malaria', 'dp', 'mSar', 'Human_HT29_Colon_Cancer_DNA', 'Human_Hepatocyte_Murine_Fibroblast']
	Number of classes: 8
torch.Size([3, 256, 256])
RESCALE_SIZE:  286
Data loader
	Root: .
	Number of images: 1975
	Classes:  ['Hela', 'synthetic_BBBC004', 'Human_USOS_P_20585', 'malaria', 'dp', 'mSar', 'Human_HT29_Colon_Cancer_DNA', 'Human_Hepatocyte_Murine_Fibroblast']
	Number of classes: 8
torch.Size([3, 256, 256])
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0171, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0416, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0406, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0501, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0442, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0349, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0442, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0653, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0685, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0495, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0470, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0495, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.1263, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0889, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0584, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0577, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0584, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.1171, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0917, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0910, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0703, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0910, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.1619, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.1398, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.2421, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0004, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(6.4909e-05, device='cuda:0', dtype=torch.float16,
       grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0002, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0002, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0002, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0002, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0002, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0002, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0003, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0002, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0002, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0002, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0002, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0004, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0003, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0002, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0002, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0002, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0004, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0004, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0003, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0003, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0003, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0005, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0005, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0006, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0988, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0135, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0305, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0353, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0452, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0309, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0271, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0309, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0511, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0632, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0296, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0322, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0296, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0560, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0756, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0409, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0340, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0409, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0689, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0858, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0678, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0497, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0678, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.1077, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.1044, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.1785, device='cuda:0', dtype=torch.float16)
INPUT IS INF IN FORWARD PASS!! tensor(526, device='cuda:0')
=== : Conv2dBlock.forward, checkpoint: 0 ===
Funit_model.py recon_criterion: SHAPE OF INPUT torch.Size([8, 3, 256, 256]) AND OF PREDICTION torch.Size([8, 3, 282, 282]) AREN'T EQUAL!
grad_output_max: tensor(0.0001, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0023, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0066, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0105, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0119, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0164, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0119, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0381, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0410, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0442, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0327, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0442, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0760, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0814, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0512, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0593, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0512, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.1146, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.1229, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0777, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.1211, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0777, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.2034, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.2179, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.3481, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0001, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0025, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0067, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0106, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0121, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0171, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0121, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0392, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0433, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0455, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0337, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0455, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0826, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0815, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0554, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0619, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0554, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.1223, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.1265, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0800, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.1237, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0800, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.2118, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.2275, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.3604, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0063, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0221, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0381, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0897, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0671, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.1099, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0671, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.2245, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.2673, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.1982, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.2268, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.1982, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.4739, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.6372, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.2969, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.5405, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.2969, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.7998, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.7500, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.4395, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.5601, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.4395, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(1.2471, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(1.4844, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(2.0039, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0076, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0258, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0454, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.1008, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0756, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.1268, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0756, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.2781, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.3298, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.2163, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.2673, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.2163, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.6606, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.8101, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.3813, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.5894, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.3813, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(1.0117, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.9863, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.4946, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.7100, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.4946, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(1.3340, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(1.6338, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(2.2852, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(28.6562, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(9.0078, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(46.5312, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(74.5625, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(32.2812, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(76.7500, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(39.0625, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(79.2500, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(31.5312, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(24.2188, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(103.4375, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(226.3750, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(64.2500, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(97.3125, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(77.8750, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(159.6250, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(18.9219, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(38.3750, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(17.8125, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(13.7500, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(11.4531, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(10.4453, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(16.1875, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(8.5547, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(8.7344, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(5.3828, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(238.2500, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(417., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(424.5000, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(486.2500, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(542.5000, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(602., device='cuda:0', dtype=torch.float16)
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 128.0
D acc: 0.3651	 G acc: 0.7500
Elapsed time in update: 47.781090
Iteration: 00000001/00100000
INPUT IS INF IN FORWARD PASS!! tensor(66, device='cuda:0')
=== : Conv2dBlock.forward, checkpoint: 0 ===
grad_output_max: tensor(0., device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0072, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0208, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0310, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0402, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0350, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0312, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0350, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0776, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0980, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0656, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0650, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0656, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.1492, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.1555, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.1069, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.1068, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.1069, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.1864, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.2030, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.1188, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.1730, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.1188, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.2698, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.3301, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.4819, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(0.0004, device='cuda:0', dtype=torch.float16)
grad_output_max: tensor(7.6115e-05, device='cuda:0', dtype=torch.float16,
       grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0002, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0006, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0009, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0012, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0015, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0012, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0067, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0076, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0058, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0101, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0101, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0069, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0108, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0069, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0167, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0182, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
grad_output_max: tensor(0.0289, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)
Elapsed time in update: 1.112986
